{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named '_file_cache'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a074e54d42ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# does this work for you and abstracts you from having to know the nitty-gritty of the Twitter API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtwitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Here we are importing the python-twitter module. (The library you import is called twitter, this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/swethakolalapudi/anaconda/lib/python3.4/site-packages/twitter/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0m_file_cache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_FileCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwitterError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdirect_message\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDirectMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named '_file_cache'"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Step 1: Accept a search term from the user and download \n",
    "# the last 100 tweets from that search term \n",
    "#####################################################################\n",
    "\n",
    "# Install the python-twitter module. Unfortunately this module works only with Python 2 currently\n",
    "# and the Python 3 support is still under development. There are other modules that are similar though and\n",
    "# some are listed on the Twitter API documentation website \n",
    "# https://dev.twitter.com/overview/api/twitter-libraries\n",
    " \n",
    "\n",
    "# Otherwise, you can just go ahead and use !pip install python-twitter to install python-twitter for Python 2.  \n",
    "# This is a module that provides a python like interface to the Twitter API. The Twitter API is \n",
    "# fairly straightforward to use if you have used REST APIs before. A REST API provides information \n",
    "# in the form of a JSON which your application will have to parse once you get it. python-twitter \n",
    "# does this work for you and abstracts you from having to know the nitty-gritty of the Twitter API. In case the \n",
    "# module that you are using provides you a json output; you can use the json library to parse the tweets. This would\n",
    "# be an additional step that we have not shown you in our script. \n",
    "\n",
    "\n",
    "import twitter\n",
    "\n",
    "# Here we are importing the python-twitter module. (The library you import is called twitter, this \n",
    "# is a bit peculiar, but just remember that you will install python-twitter but in the import statement\n",
    "# import twitter)\n",
    "\n",
    "# The module provides an API object which has methods to get information from the Twitter API. To see \n",
    "# the complete documentation type pydoc twitter.Api at the command prompt in your terminal. This will \n",
    "# show you all the methods available, including those for fetching a user's statuses, a user's followers,\n",
    "# statuses for a particular search term etc \n",
    "# You can even post a status message to Twitter using this Api object but let's not go there right now :) \n",
    "\n",
    "# The Api object will need your Twitter API key/access credentials. Get these by registering your app \n",
    "# at https://apps:twitter.com/app/new \n",
    "\n",
    "api = twitter.Api(consumer_key='tpAestpXtM2pYAlomfZr6LN7d',\n",
    "                 consumer_secret='MCQ1aVPypaBOZIlg7MDp36znULAIcmf9Cj8xfxodyVyLpILpQu',\n",
    "                 access_token_key='124163864-koQiHbqAF1QvLUzGqMb2ITvWk60jaa5yOsgJeaT7',\n",
    "                 access_token_secret='qdMSjnab0O49k1pnck0fgtVQre60VN7pb0qkSC2vSYwJE')\n",
    "\n",
    "# To see if this worked, use the command below, it will print out a bunch of details about your user account\n",
    "# and that's how you know you're all set to use the API\n",
    "print(api.VerifyCredentials())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! What are we searching for today?\"#Apple\"\n",
      "Great! We fetched 100 tweets with the term #Apple!!\n"
     ]
    }
   ],
   "source": [
    "# We're all set with our API \n",
    "# Now we'll set up a function to accept a search term and then fetch the tweets for that term \n",
    "\n",
    "def createTestData(search_string):\n",
    "    try:\n",
    "        tweets_fetched=api.GetSearch(search_string, count=100)\n",
    "        # This will return a list with twitter.Status objects. These have attributes for \n",
    "        # text, hashtags etc of the tweet that you are fetching. \n",
    "        # The full documentation again, you can see by typing pydoc twitter.Status at the \n",
    "        # command prompt of your terminal \n",
    "        print \"Great! We fetched \"+str(len(tweets_fetched))+\" tweets with the term \"+search_string+\"!!\"\n",
    "        # We will fetch only the text for each of the tweets, and since these don't have labels yet, \n",
    "        # we will keep the label empty \n",
    "        return [{\"text\":status.text,\"label\":None} for status in tweets_fetched]\n",
    "    except:\n",
    "        print \"Sorry there was an error!\"\n",
    "        return None\n",
    "    \n",
    "search_string=input(\"Hi there! What are we searching for today?\")\n",
    "testData=createTestData(search_string)\n",
    "\n",
    "# Let's try that out\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': None,\n",
       "  'text': u\"Video: Hundreds line up to snap goods in #Apple 's 26th new store in China https://t.co/sU70bSJRrn\"},\n",
       " {'label': None,\n",
       "  'text': u'#Apple podr\\xeda privar a sus iPhone 7 de un elemento importante https://t.co/35pkaCcRw8 https://t.co/sxa9EH1TKM'},\n",
       " {'label': None,\n",
       "  'text': u\"Views from the 9.3, Apple's preview for its new iOS https://t.co/OFSOqjqG1e #tech #apple\"},\n",
       " {'label': None,\n",
       "  'text': u'Top hashtags for @SunshineSpectar: #osx #app #mac #apple #ios https://t.co/hS9x3LOuv8'},\n",
       " {'label': None,\n",
       "  'text': u'Apple Music Spotify\\u2019i Sollad\\u0131\\u2026 https://t.co/hkAlIZcNY6\\n\\n#Apple #Music #Spotify #ios #Teknoloji #TDT #Teknodestekteam'},\n",
       " {'label': None,\n",
       "  'text': u'RT @alicensbi: #iTunes Gift Card Giveaway : Claim your iTunes Gift Card Code via https://t.co/jFvyxEkEIy #iphone #apple https://t.co/GnJnkf\\u2026'},\n",
       " {'label': None,\n",
       "  'text': u'Before you swear off third-party email apps for good, try N1. #Apple https://t.co/cyveGjwSKL'},\n",
       " {'label': None,\n",
       "  'text': u'Loving the new work setup! #Apple #magicmouse #beats https://t.co/iDuvy0TAdM'},\n",
       " {'label': None,\n",
       "  'text': u'RT FullTextRSS Online tool to FORWARD RSS TO EMAIL. https://t.co/ZBX0QP5Wok #seo #marketing #BaellTour2016 #Apple \\u2018under pressure\\u2019 to buil\\u2026'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Step 2: Classify each of the 100 tweets as positive or negative\n",
    "################################################################\n",
    "\n",
    "# 2a. Download a corpus of tweets to use as training data\n",
    "# We'll use Niek Sanders's Tweet Sentiment Corpus. He has kindly provided 5000+ labelled tweets\n",
    "# WE can download a csv from his website with the tweets. But there is a catch, Twitter only allows \n",
    "# sharing of the tweet_id, so we'll have to fetch the text for each tweet id from the twitter API \n",
    "\n",
    "# We'll write a function that will read the csv we got from his website, for each tweet id in the \n",
    "# csv we'll download the tweet text and then write it back to another csv \n",
    "\n",
    "def createTrainingCorpus(corpusFile,tweetDataFile):\n",
    "    import csv\n",
    "    corpus=[]\n",
    "    with open(corpusFile,'rb') as csvfile:\n",
    "        lineReader = csv.reader(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        for row in lineReader:\n",
    "            corpus.append({\"tweet_id\":row[2],\"label\":row[1],\"topic\":row[0]})\n",
    "    # We now have a list with a dictionary for each row in Sanders's csv\n",
    "    # Next let's iterate through that list and fetch the text for each tweet_id\n",
    "    \n",
    "    # If you try to download more than 180 tweets/15 mins, Twitter will rate limit you. So, use a delay\n",
    "    # to avoid being rate limited. But this means it will take 10+ hours to download all 5000 tweets \n",
    "    # We'll show you the code to download all 5000 tweets, but for now, we'll work with a smaller corpus\n",
    "    # so we won't have to wait 10 hours to see our code run :) \n",
    "    \n",
    "    # To download the full corpus \n",
    "    import time \n",
    "    rate_limit=180\n",
    "    sleep_time=900/180\n",
    "    \n",
    "    trainingData=[]\n",
    "    for tweet in corpus:\n",
    "        try:\n",
    "            status=api.GetStatus(tweet[\"tweet_id\"])\n",
    "            #Returns a twitter.Status object \n",
    "            print \"Tweet fetched\" + status.text\n",
    "            tweet[\"text\"]=status.text\n",
    "            #tweet is a dictionary which already has tweet_id and label (positive/negative/neutral)\n",
    "            # Add another attribute now, the tweet text \n",
    "            trainingData.append(tweet)\n",
    "            time.sleep(sleep_time) # to avoid being rate limited \n",
    "        except: \n",
    "            continue\n",
    "    # Once the tweets are downloaded write them to a csv, so you won't have to wait 40 hours \n",
    "    # every time you run this code :) \n",
    "    with open(tweetDataFile,'wb') as csvfile:\n",
    "        linewriter=csv.writer(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        for tweet in trainingData:\n",
    "            try:\n",
    "                linewriter.writerow([tweet[\"tweet_id\"],tweet[\"text\"],tweet[\"label\"],tweet[\"topic\"]])\n",
    "            except Exception,e:\n",
    "                print e\n",
    "    return trainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet fetchedNow all @Apple has to do is get swype on the iphone and it will be crack. Iphone that is\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetchedHilarious @youtube video - guy does a duet with @apple 's Siri. Pretty much sums up the love affair! http://t.co/8ExbnQjY\n",
      "Tweet fetched@RIM you made it too easy for me to switch to @Apple iPhone. See ya!\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedThe 16 strangest things Siri has said so far. I am SOOO glad that @Apple gave Siri a sense of humor! http://t.co/TWAeUDBp via @HappyPlace\n",
      "Tweet fetchedGreat up close & personal event @Apple tonight in Regent St store!\n",
      "Tweet fetchedFrom which companies do you experience the best customer service aside from @zappos and @apple?\n",
      "Tweet fetchedJust apply for a job at @Apple, hope they call me lol\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedLmao I think @apple is onto something magical! I am DYING!!! haha. Siri suggested where to find whores and where to hide a body lolol\n",
      "Tweet fetchedRT @PhillipRowntree: Just registered as an @apple developer... Here's hoping I can actually do it... Any help, greatly appreciated!\n",
      "Tweet fetchedWow. Great deals on refurbed #iPad (first gen) models. RT: Apple offers great deals on refurbished 1st-gen iPads http://t.co/ukWOKBGd @Apple\n",
      "Tweet fetchedJust registered as an @apple developer... Here's hoping I can actually do it... Any help, greatly appreciated!\n",
      "Tweet fetched‰Ω†Â•Ω ! Currently learning Mandarin for my upcoming trip to Hong Kong. I gotta hand it to @Apple iPhones & their uber useful flashcard apps  ÓîñÓîì\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedCome to the dark side üì±‚Äú@gretcheneclark: Hey @apple, if you send me a free iPhone, I will publicly and ceremoniously burn my #BlackBerry.‚Äù\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetchedThank you @apple for Find My Mac - just located and wiped my stolen Air. #smallvictory #thievingbastards\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedThanks to @Apple Covent Garden #GeniusBar for replacing my MacBook keyboard/cracked wristpad during my lunch break today, out of warranty.\n",
      "Tweet fetched@DailyDealChat @apple Thanks!!\n",
      "Tweet fetchediPads Replace Bound Playbooks on Some N.F.L. Teams http://t.co/2UXAWKwf @apple @nytimes\n",
      "[{u'message': u'User has been suspended.', u'code': 63}]\n",
      "Tweet fetched@apple @siri is efffing amazing!!\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedRT @TripLingo: We're one of a few \"Featured Education Apps\" on the @Apple **Website** today, sweet! http://t.co/0yWvbe1Z\n",
      "Tweet fetchedWe're one of a few \"Featured Education Apps\" on the @Apple **Website** today, sweet! http://t.co/0yWvbe1Z\n",
      "Tweet fetchedWhen you want something done right, you do it yourself... or go to @Apple. AT&T you're useless these days. #yourdaysarenumbered\n",
      "\n",
      "Ô£øÔ£øÔ£ø\n",
      "Tweet fetchedWe did an unexpected workshop for the #iPhone4S at @apple yesterday and we got an awesome amount of info #notjustaboutthephone @gamerchik16\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetched---¬ª RT @Apple No question bro. RT @AintEeenTrippin: Should I get dis iPhone or a EVO 3D?\n",
      "Tweet fetchedRT @imightbewrong: I'm OVER people bitching about the #iPhone4S... I think it's the smartest phone I've ever had and I'm very happy.   : ...\n",
      "Tweet fetchedI'm OVER people bitching about the #iPhone4S... I think it's the smartest phone I've ever had and I'm very happy.   :)  Way to go @Apple!\n",
      "Tweet fetched@Twitter CEO points to @Apple as 'corporate mentor' as @iOS signups triple http://t.co/GCY8iphN\n",
      "Tweet fetchedAt the bus with my iPhone ;) thxx @apple\n",
      "Tweet fetched@azee1v1 @apple @umber AppStore is well done, so is iTunes on the mobile devices.  I was talking about desktop app.\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedNYTimes: Coach Wants to See You. And Bring Your iPad. http://t.co/J2FTiEnG #iPad @apple set red 42 red 42 hut hut @NFL wish I had an #iPad\n",
      "Tweet fetched@apple @jilive @DanielPink: Apple sells 4 million iPhone 4S units in first weekend ... Steve Jobs brilliance lives on for ever! #iphone #RVA\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetched@bkad5161 than apologize to @apple ;)\n",
      "Tweet fetched@Apple downloads of iOS 5 are proving popular with users  -- http://t.co/NSHLfiUX\n",
      "Tweet fetchedLmfao look at the argument I had with Siri !!\n",
      "@ijustine @apple http://t.co/D4VjL7SI\n",
      "Tweet fetchedIncredible: 4 million iPhone 4Ss in 3 days. 135% better than the iPhone 4 http://t.co/1FMJxTMM @apple #iphone4s\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetchedWell @apple fixed my #ios5 battery drain problem with a replacement iPhone 4 -- it's working like a champ now\n",
      "Tweet fetchedCurrently ordering a BRAND NEW MACBOOK PRO!!! Bahhh... my MacBook is 5 years old. I'll miss it. But it's time. cc: @Apple -\n",
      "Tweet fetchedyou are so blessed. @apple\n",
      "Tweet fetched#Siri now knows who my dad, mom, brother and girlfriend is.  Thanks @apple\n",
      "Tweet fetchedWell at least the @apple store has amazing call waiting music! #need4s\n",
      "Tweet fetched#sweet... #apple replaced my glass #probono. thank you @apple\n",
      "Tweet fetchedNot Bad! @Apple Sells Over 4 Million #IPhones in Debut Weekend - Bloomberg http://t.co/AVSl3ygU - #smartphone #sm RT @VinodRad\n",
      "Tweet fetchedloving new technology from @apple iPhone 4s, mac air and iCloud are unreal #technology\n",
      "Tweet fetchedI'm loving this new IOS5 update :) @apple\n",
      "Tweet fetchedAnother mention for Apple Store: http://t.co/fiIOApKt - RT @floridamike Once again getting great customer service from the @apple store ...\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedTime to go get my iPhone 4s.  Looking forward to sticking it to the man by no longer paying for most texts.  Thanks @apple.\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetchedThank you @apple. My new gf(iphone4s) is great!  She does everything!\n",
      "Tweet fetched#iCloud set up was flawless and works like a champ! To the Cloud @Apple\n",
      "Tweet fetched@Wisconsin_Mommy @Apple I'd totally email the company... I always get great service at our @Apple store!\n",
      "Tweet fetched@apple loving the new IOS5 upgrade for the iPhone!\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetchedIs it just me or is #iOS5 faster for the iPad? @apple\n",
      "Tweet fetchedRT @cjwallace03: So apparently @apple put MB cap on your SMS with the new update. 25mb storage before it tells you your inbox is full. W ...\n",
      "Tweet fetchedRT @Jewelz2611 @mashable @apple, iphones r 2 expensive. Most went w/ htc/galaxy. No customer loyalty w/phone comp..\n",
      "Tweet fetched@mashable @apple, iphones r 2 expensive. Most went w/ htc/galaxy. No customer loyalty w/phone comp..\n",
      "Tweet fetchedTHiS IS WHAT WiLL KiLL APPLE http://t.co/72Jw4z5c RiP @APPLE\n",
      "Tweet fetched@apple why my tunes no go on my iPhone? iPhone lonely without them. silly #iOS5\n",
      "Tweet fetched@apple needs to hurry up and release #iTunesMatch\n",
      "Tweet fetchedWhy is  #Siri always down @apple\n",
      "Tweet fetchedI just need to exchange a cord at the apple store why do I have to wait for a genius? @apple\n",
      "Tweet fetched@apple AirDrop #fail - Immediate \"declined your request.\" every time\n",
      "Tweet fetchedgood article about why @apple fucked it all up with lion and their future. http://t.co/zNDP9Vr6 #fb\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetchedYellowgate? Some iPhone 4S Users Complain of Yellow Tint to Screen http://t.co/uaqrxTNk @apple @iphone4s\n",
      "Tweet fetchedThe one #iphone feature still missing since @apple first showed it.. Contacts pictures on the contacts list! Simple yet 5 major updates miss\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetched@paulens It surprises me that @Apple throws up an error alert about authorizing, and there's no \"Authorize this computer\" button.\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedFUCK YOU @apple DIE IN A FUCKING BLAZE INFERNO.\n",
      "Tweet fetchedOh, @apple. Steve obviously had nothing to do with iPhoto, as it's the perfect opposite of 'insanely great'. Get it fixed, please.\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "Tweet fetched@ryanbaldwin @apple So in iTunes I go Store -&gt; Authorise‚Ä¶ why doesn't it just auto-authorise it when I sign into iTunes? Grrrr...\n",
      "Tweet fetchedSeriously - I have absolutely no offing clue what @Apple means by \"authorization\", nor how to do it.\n",
      "Tweet fetchedBoy, could @apple make it any harder to put my purchased music from the cloud on to my new macbook pro? \"You must authorize this computer‚Ä¶\"\n",
      "Tweet fetchedshit, shit, shit. IOS5 update ate all my apps, data and media just like @apple said it would. This is going to take some time to rebuild.\n",
      "Tweet fetched. @apple & @AT&T u cannot tell me there isn't at least 1 64GB iPhone 4S in LA or Vegas!! Give me a fucking break!!!!\n",
      "Tweet fetchedLove @apple downloads. 4 hours and i-pad now wonky! #ripstevejobs #thenonsensepersists #neednewipadguide #fatfuckingchance\n",
      "Tweet fetchedDear @apple My new Air is now a notbook since your update killed #wifi #bug #destroying #productivity\n",
      "Tweet fetchedI am so done with @Att and @apple 's profitering and lack of customer service, so fucking down with both!!!\n",
      "Tweet fetchedIt would be great If @Apple would send my new phone. #frustrated\n",
      "Tweet fetched@apple thank you for ruining my 3GS with #iOS5. You've just turned my phone into an utterly useless pile of shit.\n",
      "Tweet fetched@rogerweir no but I have the option of a  replacement iPhone 4s ?\n",
      "Not sure if I want one after having 2 duff iPhones.\n",
      "@O2 @iphone4s @apple\n",
      "Tweet fetchedSo apparently @apple put MB cap on your SMS with the new update. 25mb storage before it tells you your inbox is full. What is this 2001?\n",
      "Tweet fetchedYou know @apple It's been almost a week since I paid for iTunes Match, I would really like to use it. Any ETA on a fix?\n",
      "Tweet fetchedremoving all @apple shit.\n",
      "Tweet fetchedSo @PhoenixSwinger 's iPhone 4 is giving her a hella hard time w/ the iOS5 update @apple\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetched@Apple can't send me an iPhone preordered 1hr after launching but they cans send 5 or 10 to all the jackasses who want to shoot or blend 'em\n",
      "Tweet fetchedGotta say the @Apple itouch iphone shuffle etc.. sound quality is AWFUL.. painfully crap. Its been a downgrade from @Sony sound quality wise\n",
      "Tweet fetched@bisquiat @Apple the upgrade just slows down my phone so much, it's stuck half the time. uch. thankfully no other damage. sucks for you :(\n",
      "Tweet fetched@Mayati I think @Apple didn't do such a thorough job with the step x steps for upgrade and move to iCloud. Now it's cost me mightily.\n",
      "Tweet fetchedHey @apple now I have iOS5 my iPhone doesn't include songs that are on compilation albums under the artist's name. #whaddupwitdat\n",
      "Tweet fetched@NickTheFNicon He can send but not rcve txts so he has an apt @apple at 4pm.Then he exclaims: And I waited a whole YEAR for this phone!!LMAO\n",
      "Tweet fetchedTotal chaos at @apple store regent street. Like an Ethiopian feeding station. Can't believe this is same co. that makes all that cool shit.\n",
      "Tweet fetched@FishMama: If you made a purchase, just wait for the @apple survey! hate going b/c of the bad #custserv\n",
      "Tweet fetchedCorrection: @ Best Buy kudos to Chris @ Alamo Ranch S.A. TX-fixed issues couldn't resolve after 1/2 day w/ @ATT & @Apple. Hero of my day!\n",
      "Tweet fetched@phxguy88 @Apple @BGR That's why all the ppl who stand in line for hrs to get the \"newest\" model are suckers...\n",
      "Tweet fetchedWould it kill @apple to put a braille type bump on their earbuds so we know which bud is R and L in the dark.\n",
      "Tweet fetched@APPLE Wow @MOTOROLA Just crushed your dreams....\n",
      "[{u'message': u'Sorry, you are not authorized to see this status.', u'code': 179}]\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedOh, just fuck you, @apple. Already?? ---&gt;  iPhone 5 on schedule for summer launch? http://t.co/Ofh9PTaG via @BGR\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetched@apple, \n",
      "No, I won't wait until thursday for an available appointment just so a 'genius' can tell me I'm shit out of luck. #now\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetched@Apple, on the #iPad with #iOS5, why has the Messages Icon been included when it can't be used?\n",
      "Tweet fetched@Steelo254 yea! I pre-order through @apple and they sorry too just like #AT&T\n",
      "Tweet fetchedInteresting... @apple now requires you to have a reservation ?         #apple #iphone #4S    :  http://t.co/zZK4fTii\n",
      "Tweet fetched@apple why is my iPhone battery so crappy #fail\n",
      "Tweet fetchedMy @Apple @macbook keyboard will not type :(\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "[{u'message': u'No status found with that ID.', u'code': 144}]\n",
      "Tweet fetchedWhy doesn't @apple iCloud sync Stickies? They've always been around, just nothing every progressed w/ them!! Why apple why?  @gruber\n",
      "'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 22-24: ordinal not in range(128)\n",
      "'ascii' codec can't encode characters in position 129-131: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\xbb' in position 3: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2026' in position 59: ordinal not in range(128)\n",
      "'ascii' codec can't encode character u'\\u2026' in position 137: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's now write a separate function to download just 50 tweets for each label \n",
    "\n",
    "def createLimitedTrainingCorpus(corpusFile,tweetDataFile):\n",
    "    import csv\n",
    "    corpus=[]\n",
    "    with open(corpusFile,'rb') as csvfile:\n",
    "        lineReader = csv.reader(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        for row in lineReader:\n",
    "            corpus.append({\"tweet_id\":row[2],\"label\":row[1],\"topic\":row[0]})\n",
    "    # We now have a list with a dictionary for each row in Sanders's csv\n",
    "    # Next let's iterate through that list and fetch the text for each tweet_id\n",
    "    \n",
    "    # If you try to download more than 180 tweets/15 min, Twitter will rate limit you. So, use a delay\n",
    "    # to avoid being rate limited. But this means it will take 10+ hours to download all 5000 tweets \n",
    "    # We'll show you the code to download all 5000 tweets, but for now, we'll work with a smaller corpus\n",
    "    # so we won't have to wait 10 hours to see our code run :) \n",
    "    \n",
    "    # To download the full corpus \n",
    "    \n",
    "    trainingData=[]\n",
    "    for label in [\"positive\",\"negative\"]:\n",
    "        i=1\n",
    "        for tweet in corpus:\n",
    "            if tweet[\"label\"]==label and i<=50:\n",
    "                try:\n",
    "                    status=api.GetStatus(tweet[\"tweet_id\"])\n",
    "                    #Returns a twitter.Status object \n",
    "                    print \"Tweet fetched\" + status.text\n",
    "                    tweet[\"text\"]=status.text\n",
    "                    #tweet is a dictionary which already has tweet_id and label (positive/negative/neutral)\n",
    "                    # Add another attribute now, the tweet text \n",
    "                    trainingData.append(tweet)\n",
    "                    i=i+1\n",
    "                except Exception, e: \n",
    "                    print e\n",
    "                    \n",
    "    # Once the tweets are downloaded write them to a csv, so you won't have to wait 10 hours \n",
    "    # every time you run this code :) \n",
    "    with open(tweetDataFile,'wb') as csvfile:\n",
    "        linewriter=csv.writer(csvfile,delimiter=',',quotechar=\"\\\"\")\n",
    "        # We'll add a try catch block here so that we still get the training data even if the write \n",
    "        # fails \n",
    "        for tweet in trainingData:\n",
    "            try:\n",
    "                linewriter.writerow([tweet[\"tweet_id\"],tweet[\"text\"],tweet[\"label\"],tweet[\"topic\"]])\n",
    "            except Exception,e:\n",
    "                print e\n",
    "    return trainingData\n",
    "\n",
    "corpusFile=\"/Users/swethakolalapudi/Downloads/sanders-twitter-0.2/corpus.csv\"\n",
    "tweetDataFile=\"/Users/swethakolalapudi/Downloads/sanders-twitter-0.2/tweetDataFile.csv\"\n",
    "\n",
    "trainingData=createLimitedTrainingCorpus(corpusFile,tweetDataFile)\n",
    "# This will have saved our 150 tweets to a file and also returned a list with all the tweet data we \n",
    "# need for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2b. A class to preprocess all the tweets, both test and training\n",
    "# We will use regular expressions and NLTK for preprocessing \n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "\n",
    "class PreProcessTweets:\n",
    "    def __init__(self):\n",
    "        self._stopwords=set(stopwords.words('english')+list(punctuation)+['AT_USER','URL'])\n",
    "        \n",
    "    def processTweets(self,list_of_tweets):\n",
    "        # The list of tweets is a list of dictionaries which should have the keys, \"text\" and \"label\"\n",
    "        processedTweets=[]\n",
    "        # This list will be a list of tuples. Each tuple is a tweet which is a list of words and its label\n",
    "        for tweet in list_of_tweets:\n",
    "            processedTweets.append((self._processTweet(tweet[\"text\"]),tweet[\"label\"]))\n",
    "        return processedTweets\n",
    "    \n",
    "    def _processTweet(self,tweet):\n",
    "        # 1. Convert to lower case\n",
    "        tweet=tweet.lower()\n",
    "        # 2. Replace links with the word URL \n",
    "        tweet=re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)     \n",
    "        # 3. Replace @username with \"AT_USER\"\n",
    "        tweet=re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "        # 4. Replace #word with word \n",
    "        tweet=re.sub(r'#([^\\s]+)',r'\\1',tweet)\n",
    "        # You can do further cleanup as well if you like, replace \n",
    "        # repetitions of characters, for ex: change \"huuuuungry\" to \"hungry\"\n",
    "        # We'll leave that as an exercise for you on regular expressions\n",
    "        tweet=word_tokenize(tweet)\n",
    "        # This tokenizes the tweet into a list of words \n",
    "        # Let's now return this list minus any stopwords \n",
    "        return [word for word in tweet if word not in self._stopwords]\n",
    "    \n",
    "tweetProcessor=PreProcessTweets()\n",
    "ppTrainingData=tweetProcessor.processTweets(trainingData)\n",
    "ppTestData=tweetProcessor.processTweets(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2c. Extract features and train your classifier\n",
    "\n",
    "# We'll use two methods - Naive Bayes and Support Vector Machines \n",
    "\n",
    "import nltk \n",
    "# Naive Bayes Classifier - We'll use NLTK's built in classifier to perform the classification\n",
    "\n",
    "# First build a vocabulary \n",
    "def buildVocabulary(ppTrainingData):\n",
    "    all_words=[]\n",
    "    for (words,sentiment) in ppTrainingData:\n",
    "        all_words.extend(words)\n",
    "    # This will give us a list in which all the words in all the tweets are present\n",
    "    # These have to be de-duped. Each word occurs in this list as many times as it \n",
    "    # appears in the corpus \n",
    "    wordlist=nltk.FreqDist(all_words)\n",
    "    # This will create a dictionary with each word and its frequency\n",
    "    word_features=wordlist.keys()\n",
    "    # This will return the unique list of words in the corpus \n",
    "    return word_features\n",
    "\n",
    "# NLTK has an apply_features function that takes in a user-defined function to extract features \n",
    "# from training data. We want to define our extract features function to take each tweet in \n",
    "# The training data and represent it with the presence or absence of a word in the vocabulary \n",
    "\n",
    "def extract_features(tweet):\n",
    "    tweet_words=set(tweet)\n",
    "    features={}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word]=(word in tweet_words)\n",
    "        # This will give us a dictionary , with keys like 'contains word1' and 'contains word2'\n",
    "        # and values as True or False \n",
    "    return features \n",
    "\n",
    "# Now we can extract the features and train the classifier \n",
    "word_features = buildVocabulary(ppTrainingData)\n",
    "trainingFeatures=nltk.classify.apply_features(extract_features,ppTrainingData)\n",
    "# apply_features will take the extract_features function we defined above, and apply it it \n",
    "# each element of ppTrainingData. It automatically identifies that each of those elements \n",
    "# is actually a tuple , so it takes the first element of the tuple to be the text and \n",
    "# second element to be the label, and applies the function only on the text \n",
    "\n",
    "NBayesClassifier=nltk.NaiveBayesClassifier.train(trainingFeatures)\n",
    "# We now have a classifier that has been trained using Naive Bayes\n",
    "\n",
    "# Support Vector Machines \n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# We have to change the form of the data slightly. SKLearn has a CountVectorizer object. \n",
    "# It will take in documents and directly return a term-document matrix with the frequencies of \n",
    "# a word in the document. It builds the vocabulary by itself. We will give the trainingData \n",
    "# and the labels separately to the SVM classifier and not as tuples. \n",
    "# Another thing to take care of, if you built the Naive Bayes for more than 2 classes, \n",
    "# SVM can only classify into 2 classes - it is a binary classifier. \n",
    "\n",
    "svmTrainingData=[' '.join(tweet[0]) for tweet in ppTrainingData]\n",
    "# Creates sentences out of the lists of words \n",
    "\n",
    "vectorizer=CountVectorizer(min_df=1)\n",
    "X=vectorizer.fit_transform(svmTrainingData).toarray()\n",
    "# We now have a term document matrix \n",
    "vocabulary=vectorizer.get_feature_names()\n",
    "\n",
    "# Now for the twist we are adding to SVM. We'll use sentiwordnet to add some weights to these \n",
    "# features \n",
    "\n",
    "swn_weights=[]\n",
    "\n",
    "for word in vocabulary:\n",
    "    try:\n",
    "        # Put this code in a try block as all the words may not be there in sentiwordnet (esp. Proper\n",
    "        # nouns). Look for the synsets of that word in sentiwordnet \n",
    "        synset=list(swn.senti_synsets(word))\n",
    "        # use the first synset only to compute the score, as this represents the most common \n",
    "        # usage of that word \n",
    "        common_meaning =synset[0]\n",
    "        # If the pos_Score is greater, use that as the weight, if neg_score is greater, use -neg_score\n",
    "        # as the weight \n",
    "        if common_meaning.pos_score()>common_meaning.neg_score():\n",
    "            weight=common_meaning.pos_score()\n",
    "        elif common_meaning.pos_score()<common_meaning.neg_score():\n",
    "            weight=-common_meaning.neg_score()\n",
    "        else: \n",
    "            weight=0\n",
    "    except: \n",
    "        weight=0\n",
    "    swn_weights.append(weight)\n",
    "\n",
    "\n",
    "# Let's now multiply each array in our original matrix with these weights \n",
    "# Initialize a list\n",
    "\n",
    "swn_X=[]\n",
    "for row in X: \n",
    "    swn_X.append(np.multiply(row,np.array(swn_weights)))\n",
    "# Convert the list to a numpy array \n",
    "swn_X=np.vstack(swn_X)\n",
    "\n",
    "\n",
    "# We have our documents ready. Let's get the labels ready too. \n",
    "# Lets map positive to 1 and negative to 2 so that everything is nicely represented as arrays \n",
    "labels_to_array={\"positive\":1,\"negative\":2}\n",
    "labels=[labels_to_array[tweet[1]] for tweet in ppTrainingData]\n",
    "y=np.array(labels)\n",
    "\n",
    "# Let's now build our SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "SVMClassifier=SVC()\n",
    "SVMClassifier.fit(swn_X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 2d: Run the classifier on the 100 downloaded tweets \n",
    "\n",
    "# First Naive Bayes \n",
    "NBResultLabels=[NBayesClassifier.classify(extract_features(tweet[0])) for tweet in ppTestData]\n",
    "\n",
    "# Now SVM \n",
    "SVMResultLabels=[]\n",
    "for tweet in ppTestData:\n",
    "    tweet_sentence=' '.join(tweet[0])\n",
    "    svmFeatures=np.multiply(vectorizer.transform([tweet_sentence]).toarray(),np.array(swn_weights))\n",
    "    SVMResultLabels.append(SVMClassifier.predict(svmFeatures)[0])\n",
    "    # predict() returns  a list of numpy arrays, get the first element of the first array \n",
    "    # there is only 1 element and array\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Result Positive Sentiment88%\n",
      "SVM Result Negative Sentiment92%\n"
     ]
    }
   ],
   "source": [
    "# Step 3 : GEt the majority vote and print the sentiment \n",
    "\n",
    "if NBResultLabels.count('positive')>NBResultLabels.count('negative'):\n",
    "    print \"NB Result Positive Sentiment\" + str(100*NBResultLabels.count('positive')/len(NBResultLabels))+\"%\"\n",
    "else: \n",
    "    print \"NB Result Negative Sentiment\" + str(100*NBResultLabels.count('negative')/len(NBResultLabels))+\"%\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if SVMResultLabels.count(1)>SVMResultLabels.count(2):\n",
    "    print \"SVM Result Positive Sentiment\" + str(100*SVMResultLabels.count(1)/len(SVMResultLabels))+\"%\"\n",
    "else: \n",
    "    print \"SVM Result Negative Sentiment\" + str(100*SVMResultLabels.count(2)/len(SVMResultLabels))+\"%\"\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': None,\n",
       "  'text': u\"Video: Hundreds line up to snap goods in #Apple 's 26th new store in China https://t.co/sU70bSJRrn\"},\n",
       " {'label': None,\n",
       "  'text': u'#Apple podr\\xeda privar a sus iPhone 7 de un elemento importante https://t.co/35pkaCcRw8 https://t.co/sxa9EH1TKM'},\n",
       " {'label': None,\n",
       "  'text': u\"Views from the 9.3, Apple's preview for its new iOS https://t.co/OFSOqjqG1e #tech #apple\"},\n",
       " {'label': None,\n",
       "  'text': u'Top hashtags for @SunshineSpectar: #osx #app #mac #apple #ios https://t.co/hS9x3LOuv8'},\n",
       " {'label': None,\n",
       "  'text': u'Apple Music Spotify\\u2019i Sollad\\u0131\\u2026 https://t.co/hkAlIZcNY6\\n\\n#Apple #Music #Spotify #ios #Teknoloji #TDT #Teknodestekteam'},\n",
       " {'label': None,\n",
       "  'text': u'RT @alicensbi: #iTunes Gift Card Giveaway : Claim your iTunes Gift Card Code via https://t.co/jFvyxEkEIy #iphone #apple https://t.co/GnJnkf\\u2026'},\n",
       " {'label': None,\n",
       "  'text': u'Before you swear off third-party email apps for good, try N1. #Apple https://t.co/cyveGjwSKL'},\n",
       " {'label': None,\n",
       "  'text': u'Loving the new work setup! #Apple #magicmouse #beats https://t.co/iDuvy0TAdM'},\n",
       " {'label': None,\n",
       "  'text': u'RT FullTextRSS Online tool to FORWARD RSS TO EMAIL. https://t.co/ZBX0QP5Wok #seo #marketing #BaellTour2016 #Apple \\u2018under pressure\\u2019 to buil\\u2026'},\n",
       " {'label': None,\n",
       "  'text': u'#iphone #iphone6s #apple #android #marketing #chat #facebook #ios #free #samsung https://t.co/f5pkBBUQdf https://t.co/aljrR5ANpT'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'positive']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBResultLabels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 1, 2, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMResultLabels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Looks like most of these tweets are actually neutral , And our SVM is classifying them as -ve,\n",
    "# But it classified the positive tweet correctly. \n",
    "\n",
    "# A few next steps possible here \n",
    "# Remove all neutral words according to sentiwordnet from the vocabulary. \n",
    "# Look at things like ALL CAPS , emoticons etc \n",
    "\n",
    "# GEt a corpus with more varied tweets (This one has only tech related tweets, so it works for our \n",
    "# search term (Apple) but might not for others. )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
