{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Let's create an example html to play with \n",
    "\n",
    "html=['<html><heading style=\"font-size:20px\"><i>This is the title<br><br></i></heading>',\n",
    "     '<body><b>This is the body</b><p id=\"para1\">This is para1<a href=\"www.google.com\">Google</a></p>',\n",
    "     '<p id=\"para2\">This is para 2</p></body></html>']\n",
    "html=''.join(html)\n",
    "# This just creates one string out of the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <heading style=\"font-size:20px\">\n",
      "   <i>\n",
      "    This is the title\n",
      "    <br/>\n",
      "    <br/>\n",
      "   </i>\n",
      "  </heading>\n",
      "  <b>\n",
      "   This is the body\n",
      "  </b>\n",
      "  <p id=\"para1\">\n",
      "   This is para1\n",
      "   <a href=\"www.google.com\">\n",
      "    Google\n",
      "   </a>\n",
      "  </p>\n",
      "  <p id=\"para2\">\n",
      "   This is para 2\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a soup object. This automatically identifies a structure in the html and creates a parse tree\n",
    "# you can navigate the structure/tree in the soup and extract pieces that you are interested in \n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "# You can now print this html in a formatted, easy-to-read view\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'html'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the top of the hierarchy in the parse tree is the <html></html> tag\n",
    "# Then comes the <body></body> tag\n",
    "# Within the body, the heading and paragraphs are 'siblings'\n",
    "# The body is the parent of these tags and the html tag is the parent of the body tag \n",
    "# Each tag has attributes - name, contents (a list), text, parent and siblings \n",
    "\n",
    "# name attribute is just the name of the tag \n",
    "soup.html.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'body'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'This is the bodyThis is para1GoogleThis is para 2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text attribute will mush together all the text in all the children of that tag\n",
    "soup.body.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<heading style=\"font-size:20px\"><i>This is the title<br><br/></br></i></heading>,\n",
       " <body><b>This is the body</b><p id=\"para1\">This is para1<a href=\"www.google.com\">Google</a></p><p id=\"para2\">This is para 2</p></body>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contents is a list of the children of that tag\n",
    "# In our example, the html tag has only 1 child, the body tag has 4 children \n",
    "soup.html.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>This is the body</b>,\n",
       " <p id=\"para1\">This is para1<a href=\"www.google.com\">Google</a></p>,\n",
       " <p id=\"para2\">This is para 2</p>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'html'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parent and siblings referencing helps you navigate the parse tree\n",
    "soup.body.parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"para1\">This is para1<a href=\"www.google.com\">Google</a></p>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.b.nextSibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>This is the body</b>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.previousSibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<b>This is the body</b>]\n"
     ]
    }
   ],
   "source": [
    "# findAll, find are methods to search the tree for specific tags, or tags with certain attributes \n",
    "\n",
    "bold = soup.findAll('b')\n",
    "# This will find all the tags which have the text in bold (enclosed in <b></b> tags) and return a list\n",
    "print(bold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the body\n"
     ]
    }
   ],
   "source": [
    "# to extract only the text, take each element of this list and get the text attribute\n",
    "print(bold[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is para1Google This is para 2\n"
     ]
    }
   ],
   "source": [
    "# Let's get all the text that is in the paragraphs (enclosed in <p></p> tags) as a single string \n",
    "paras = ' '.join([p.text for p in soup.findAll('p')])\n",
    "print(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'This is para 2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# findAll can look for attributes as well. Let's find the text for the paragraph with id 'para2'\n",
    "soup.findAll(id=\"para2\")[0].text\n",
    "#soup.findAll gives us a list, we pick the first element (there is only 1 element in this case) and print the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the title\n"
     ]
    }
   ],
   "source": [
    "# Let's find any text with font size 20\n",
    "\n",
    "font20=' '.join([p.text for p in soup.findAll(style=\"font-size:20px\")])\n",
    "print(font20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>This is the body</b>,\n",
       " <p id=\"para1\">This is para1<a href=\"www.google.com\">Google</a></p>,\n",
       " <p id=\"para2\">This is para 2</p>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also pass in a list or a dictionary of tag names to search for \n",
    "soup.findAll(['b','p'])\n",
    "soup.findAll({'b':True,'p':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"www.google.com\">Google</a>\n"
     ]
    }
   ],
   "source": [
    "# Let's see how we can find links. This is super-useful - say you want to find all the links on a page and iterate through\n",
    "# them to do some scraping for each of those links \n",
    "links = soup.find('a')\n",
    "\n",
    "# Links are generally of the form <a href='link'>'link-text'</a>\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notice how we used find instead of findAll - this will just give us the first tag that matches the search, in this\n",
    "# case we have only 1 link on our page. soup.findAll will return a list of links and you can limit the number of \n",
    "# results using the limit keyword soup.findAll('a',limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.google.com is the url and Google is the text\n"
     ]
    }
   ],
   "source": [
    "# Let's extract the url and the text separately \n",
    "print(links['href']+\" is the url and \"+links.text+\" is the text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'This is para 2'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find can navigate the parse tree as well. findParents, findNextSiblings,findPreviousSiblings all work \n",
    "# similar to findAll, but will search only within those branches of the tree. \n",
    "# findNext, findPrevious and findAllNext and findAllPrevious can be used to find matches starting from \n",
    "# a specified point. \n",
    "\n",
    "# Let's say you want the text of the first paragraph after the first occurrence of the text \"Google\" \n",
    "\n",
    "soup.find(text=\"Google\").findNext('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"para1\">This is para1<a href=\"www.google.com\">Google</a></p>,\n",
       " <p id=\"para2\">This is para 2</p>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little shortcut to using findAll - if you call the tag itself as a function, you can use it in place of findAll\n",
    "# with the same arguments \n",
    "\n",
    "soup.body('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"para1\">This is para1<a href=\"www.google.com\">Google</a></p>,\n",
       " <p id=\"para2\">This is para 2</p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BeautifulSoup makes parsing html or xml very intuitive and elegant. Doing the same thing with regular expressions \n",
    "# is prone to leading you to pulling your hair out :) In most situations for screen-scraping projects, BeautifulSoup\n",
    "# is a life-saver! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
